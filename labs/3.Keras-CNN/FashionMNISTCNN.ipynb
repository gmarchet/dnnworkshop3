{"cells":[{"cell_type":"markdown","source":["###Databricks notebook to run a deep learning CNN model to classify fashion items\n\nThis notebook steps through how to implement an image recognition model using a convolutional network. It starts with a basic CNN architecture to classify fashion from the Fashion MNIST data set found here: https://github.com/zalandoresearch/fashion-mnist. The data set consists of images (28*28 in size) in 10 different categories. There are 60,000 images for training and 10,000 images for testing. There are optional steps in the notebook to demonstrate use of more advanced network features. \n    \nThe model is built using Tensorflow and Keras and assumes you are running on a Databricks cluster and machine learning libraries have been pre-installed. \n\nThis notebook is adapted from work published here: \n   (1) https://github.com/amynic/azureml-sdk-fashion and \n   (2) https://github.com/Microsoft/CNTK/tree/v2.0/Tutorials."],"metadata":{}},{"cell_type":"markdown","source":["### Import core libraries and specify tensorflow and keras"],"metadata":{}},{"cell_type":"code","source":["import tensorflow as tf\nimport os\nimport time\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\nprint(\"tensorflow Version is: \" + str(tf.__version__))\n\nimport numpy as np\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nfrom keras import backend as K\nprint(os.environ['KERAS_BACKEND'])"],"metadata":{"collapsed":false},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Import the required Keras functions that will be used to create the CNN\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import utils, losses, optimizers\nimport matplotlib.pyplot as plt"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Load the Fashion MNIST data set and visualize an image\n\nThe fasion MNIST data set is included with the Keras library so we need to pull it into a training and test datasets. Each image is associated with a label from 1 of 10 classifications: \n  * Label 0: T-shirt/top\n  * Label 1: Trouser \n  * Label 2: Pullover \n  * Label 3: Dress \n  * Label 4: Coat \n  * Label 5: Sandal \n  * Label 6: Shirt \n  * Label 7: Sneaker \n  * Label 8: Bag \n  * Label 9: Ankle boot"],"metadata":{}},{"cell_type":"code","source":["# Data for training and testing\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\nprint(x_train.shape, 'train set')\nprint(x_test.shape, 'test set')\n\n# Define the text labels\nfashion_mnist_labels = [\"Top\",          # index 0\n                        \"Trouser\",      # index 1\n                        \"Jumper\",       # index 2 \n                        \"Dress\",        # index 3 \n                        \"Coat\",         # index 4\n                        \"Sandal\",       # index 5\n                        \"Shirt\",        # index 6 \n                        \"Trainer\",      # index 7 \n                        \"Bag\",          # index 8 \n                        \"Ankle boot\"]   # index 9\n\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Visualize an image. To visualize a different image, set the index to any value between 0 and 59999\nimg_index=8\n\n# Display an image from the data set\nlabel_index = y_train[img_index]\nplt.imshow(x_train[img_index])\nplt.title(fashion_mnist_labels[label_index])\n \ndisplay()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Normalize and prepare the data\n\nThe data set is loaded into memory and will be normalized so the pixel values in each image range between 0-1 instead of 0-255 pixels. This will help the model converge faster because it is working with smaller numbers.\n\nIn this section we also one-hot encode the labels for each image. This is done so the model does not treat the label (fashion category) with an implied numeric ranking. For instance, T-Shirts are labeled '0' and Sneakers are labeled '7'. We don't want the model to interpret these values with any numeric ranking. An array will be created and each image will be represented in the array with a '1' corresponding to its label. For instance, an image with an array that looks like this: array([0,0,0,0,0,0,0,0,0,1]) means the image label corresponds to the 9th index which is 'ankle boots'."],"metadata":{}},{"cell_type":"code","source":["# Set number of categories\nnum_classes = 10\n\n# Set image input dimensions \nimg_rows,img_cols = 28,28\n\n# Reshape the array without changing the data.  \n# Parameters = number of elements in the input array, the new shape (28*28), and the order \nx_train = x_train.reshape(60000, img_rows, img_cols, 1)\nx_test = x_test.reshape(10000, img_rows, img_cols, 1)\n\n# Type convert and scale the data\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\n# Save the labels for the confusion matrix later\ntest_labels = y_test\nprint(test_labels)\n\n# One-hot encoding of images\n# This creates an array equal to the number of labels (fashion categories).  Each image\n# is represented in the vector with a 1 corresponding to it's label.  \ny_train = utils.to_categorical(y_train, num_classes)\ny_test = utils.to_categorical(y_test, num_classes)\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Define the CNN network architecture\nWe will use the sequential API and compile the model with a common algorithm and loss metric.\n\nAfter running through the experiment, consider coming back to this section and changing some of the parameters, re-run the code, and see how the model and accuracy change."],"metadata":{}},{"cell_type":"code","source":["#First, set some parameters\n\nnum_classes = 10\n\n# Sample size that will be processed independently, in parallel\nbatch_size = 256\n\n#Define the CNN model as a sequential model. Every layer passes data forward to the next layer in the network. \nmodel = Sequential()\n\n# First convolutional layer uses the kernels/filters to extract features and passes them to the next layer.\nmodel.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(28,28,1)))\n\n# Pooling layer reduces dimensionality, helps to avoid overfitting\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\n\n#model.add(Dropout(0.5))\n\n# Add final, fully connected layer.  Image will be classified into one of the fashion classes.  \nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=losses.categorical_crossentropy,\n              optimizer=optimizers.Adam(),\n              metrics=['accuracy'])\n\n# Verify model architecture is as expected\nmodel.summary()\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["###Train the model\nTo train the model, use the fit() method in Keras. This code compiles the CNN model, assigns a common optimizer and loss function and identifies the output metrics to be shown.   \nA timer is started to show how long the model takes to run. The test data set is passed in as the validation set so we can see how the accuracy differs between the training set and the validation set."],"metadata":{}},{"cell_type":"code","source":["# Train the model and return loss and accuracy for each epoch\n\n# The number of training passes\nepochs = 6\n\n# Batch size is the sample size that will be processed independently, in parallel\nbatch_size = 256\n\nstart = time.time()\nhist = model.fit(x_train, y_train, \n                  batch_size=batch_size, \n                  epochs=epochs, verbose=1)\nend = time.time()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Print how long it took to train the  model\nprint('Time to train model (sec): ', (end-start))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Score the model"],"metadata":{}},{"cell_type":"code","source":["# Evaluate the model on the test data\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy: ', score[1])"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["###Plot model evaluation metrics"],"metadata":{}},{"cell_type":"code","source":["# Plot model accuracy across the epochs \n\naccuracy = hist.history['acc']\n\nepochs = range(len(accuracy))\n\nfig = plt.figure()\nplt.plot(epochs, accuracy, 'bo')\nplt.title('Training accuracy')\nplt.legend()\n\ndisplay(fig)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Plot model loss across the epochs\n\nloss = hist.history['loss']\n\nfig = plt.figure()\nplt.plot(epochs, loss, 'bo')\nplt.title('Training loss')\nplt.legend()\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["### Predict labels for 15 images from test set"],"metadata":{}},{"cell_type":"code","source":["# Run this code to see if the labels for each of 15 images was predicted correctly\npredictions = model.predict(x_test)\n\n# Plot a random sample of 15 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = np.argmax(predictions[index])\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n                                  fashion_mnist_labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))\n# Visualize in databricks\ndisplay()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["###Create and display a confusion matrix"],"metadata":{}},{"cell_type":"code","source":["# Import the libraries needed to create the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport itertools"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Create a confusion matrix to see how the predicted labels did compared to the true labels\n\n# Rather than using the explicit probabilities generated by the prediction method,\n# round the numbers  \nrounded_predictions = model.predict_classes(x_test)\n\n#print(rounded_predictions)\n#print(test_labels)\n\n# Test labels were created in the data pre-processing step \ncm = confusion_matrix(test_labels, rounded_predictions)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Confusion matrix code borrowed from here: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\ndef plot_confusion_matrix( cm, classes,\n                           normalize=False,\n                           title='Confusion matrix',\n                           cmap=plt.cm.Blues):\n  \n  # This function prints and plots the confusion matrix\n \n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n \n    # If normalize, plot the raw numbers, otherwise plot the rounded numbers \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print('Normlaized confusion matrix')\n    else:\n        print(\"Confusion matrix, without normalization\")\n   \n    # Text prints out in white the number of true predictions and\n    # black for the number of false predictions  \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, cm[i,j],\n        horizontalalignment=\"center\",\n        color=\"white\" if cm[i,j] > thresh else \"black\")\n             \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')           \n      \n \ncm_plot_labels = fashion_mnist_labels\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\ndisplay()                           "],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["###Show the impact of changing the activation function\n\nTo easily see the impact of changing the activation function, a python function is defined below to construct, compile, train, and score a model."],"metadata":{}},{"cell_type":"code","source":["def runCNN(activation, verbose):\n\n  img_rows, img_cols = 28, 28\n  input_shape = (img_rows, img_cols, 1)\n  epochs = 1\n\n  # Build the CNN\n  model = Sequential()\n  \n  # Convolution Layer\n  model.add(Conv2D(64, kernel_size=(3, 3),\n                 activation=activation,\n                 input_shape = (28,28,1))) \n  \n  # Pooling with stride (2, 2)\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  \n  model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\n  model.add(MaxPooling2D(pool_size=(2,2)))\n\n  # Flatten layer\n  model.add(Flatten())\n  model.add(Dense(128, activation='relu'))\n\n   # Randomly delete 50% of neurons to avoid overfitting  \n  model.add(Dropout(0.5))\n  \n   # Apply softmax\n  model.add(Dense(num_classes, activation='softmax'))\n \n  # Loss function (crossentropy) and Optimizer (Adam)\n  model.compile(loss = losses.categorical_crossentropy,\n              optimizer = optimizers.Adam(),\n              metrics=['accuracy'])\n \n  # Train model\n  model.fit(x_train, y_train, \n                batch_size=batch_size, \n                epochs=epochs, verbose=0)\n\n  # Evaluate model\n  score = model.evaluate(x_test, y_test, verbose=0)\n  \n  # Return\n  return score"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Sigmoid activation  \n\nscore_sigmoid = runCNN('sigmoid', 0)\nprint('Sigmoid, Test loss:', score_sigmoid[0])\nprint('Sigmoid, Test accuracy:', score_sigmoid[1])\n"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Tanh activation\n\nscore_tanh = runCNN('tanh', 0)\nprint('tanh, Test loss:', score_tanh[0])\nprint('tanh, Test accuracy:', score_tanh[1])\n"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# Relu activation\n\nscore_sigmoid = runCNN('sigmoid', 0)\nprint('Sigmoid, Test loss:', score_sigmoid[0])\nprint('Sigmoid, Test accuracy:', score_sigmoid[1])\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.2","nbconvert_exporter":"python","file_extension":".py"},"name":"FashionMNISTCNN","notebookId":2004262879760850,"kernelspec":{"display_name":"Python [myenv]","language":"python","name":"Python [myenv]"},"anaconda-cloud":{}},"nbformat":4,"nbformat_minor":0}
